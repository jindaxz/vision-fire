{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad6e204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvcc: command not found\n",
      "gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "/bin/bash: nvidia-smi: command not found\n",
      "/work/van-speech-nlp/jindaznb/j-vis\n",
      "System Prefix: /work/van-speech-nlp/jindaznb/visenv\n",
      "HOME: /work/van-speech-nlp/jindaznb/j-vis\n",
      "2.0.0+cu117 False\n",
      "3.3.0\n",
      "11.7\n",
      "GCC 9.3\n"
     ]
    }
   ],
   "source": [
    "%run 1-0mmyolo-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c81a8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Write custom Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d024c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/j-vis/mmdetection\n"
     ]
    }
   ],
   "source": [
    "# %cd {HOME}/mmyolo\n",
    "%cd {HOME}/mmdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfeef84-c3fb-4329-ba12-9b61a5c9d535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/j-vis/mmdetection/configs/faster_rcnn/custom-faster-rcnn_r50_fpn_1x_coco-mutiscale.py\n"
     ]
    }
   ],
   "source": [
    "model_folder=\"faster_rcnn\"\n",
    "base_model_name=\"faster-rcnn_r50_fpn_1x_coco\"\n",
    "custom_model_name=f\"custom-{base_model_name}-mutiscale\"\n",
    "CUSTOM_CONFIG_PATH = f\"{HOME}/mmdetection/configs/{model_folder}/{custom_model_name}.py\"\n",
    "print(CUSTOM_CONFIG_PATH)\n",
    "\n",
    "\n",
    "CUSTOM_CONFIG = f\"\"\"\n",
    "_base_ = './{base_model_name}.py'\n",
    "\n",
    "# ========================Frequently modified parameters======================\n",
    "# -----data related-----\n",
    "model = dict(\n",
    "    roi_head=dict(\n",
    "        bbox_head=dict(num_classes={num_classes}),\n",
    "))\n",
    "\n",
    "dataset_type = 'COCODataset'\n",
    "classes =  {classes}\n",
    "\n",
    "data_root = '{dataset_location}' # Root directory of the dataset\n",
    "\n",
    "train_ann_file = 'train/_annotations.coco.json'  # Annotation file for training set\n",
    "train_data_prefix = 'train/'  # Prefix for training data directory\n",
    "\n",
    "val_ann_file = 'valid/_annotations.coco.json'  # Annotation file for validation set\n",
    "val_data_prefix = 'valid/'  # Prefix for validation data directory\n",
    "\n",
    "class_name = {classes} \n",
    "num_classes = {num_classes}  # Number of classes in the dataset\n",
    "metainfo = dict(classes=class_name, palette=[(20, 220, 60)])  # Metadata information for visualization\n",
    "\n",
    "train_batch_size_per_gpu = {BATCH_SIZE}  # Batch size per GPU during training\n",
    "#train_num_workers = 4  # Number of worker processes for data loading during training\n",
    "persistent_workers = True  # Whether to use persistent workers during training\n",
    "\n",
    "# -----train val related-----\n",
    "# base_lr = 0.004  # Base learning rate for optimization\n",
    "base_lr = 0.04\n",
    "max_epochs = {MAX_EPOCHS}  # Maximum training epochs\n",
    "num_epochs_stage2 = 20  # Number of epochs for stage 2 training\n",
    "\n",
    "model_test_cfg = dict(\n",
    "    multi_label=True,  # Multi-label configuration for multi-class prediction\n",
    "    nms_pre=30000,  # Number of boxes before NMS\n",
    "    score_thr=0.001,  # Score threshold to filter out boxes\n",
    "    nms=dict(type='nms', iou_threshold=0.65),  # NMS type and threshold\n",
    "    max_per_img=300)  # Maximum number of detections per image\n",
    "\n",
    "\n",
    "# ========================Possible modified parameters========================\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        type=\"CheckpointHook\",\n",
    "        save_best=\"coco/bbox_mAP_50\",\n",
    "        rule=\"greater\",\n",
    "        max_keep_ckpts=10,\n",
    "    ),\n",
    "    early_stopping=dict(\n",
    "        type=\"EarlyStoppingHook\",\n",
    "        monitor=\"coco/bbox_mAP_50\",\n",
    "        patience=15,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_cfg=dict(\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "\n",
    "data = dict(\n",
    "    samples_per_gpu=8,\n",
    "    #workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='train/',\n",
    "        classes=classes,\n",
    "        img_scale=[(1333, 800), (1666, 1000)], # mutiscale\n",
    "        ann_file='train/_annotations.coco.json.json'),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='valid/',\n",
    "        img_scale=(1333, 800),\n",
    "        classes=classes,\n",
    "        ann_file='valid/_annotations.coco.json'),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        img_scale=(1333, 800),\n",
    "        img_prefix='test/',\n",
    "        classes=classes,\n",
    "        ann_file='test/_annotations.coco.json'))\n",
    "\n",
    "# -----data related-----\n",
    "img_scale = (1024, 1024)  # width, height\n",
    "# ratio range for random resize\n",
    "random_resize_ratio_range = (0.1, 2.0)\n",
    "# Cached images number in mosaic\n",
    "mosaic_max_cached_images = 40\n",
    "# Number of cached images in mixupep\n",
    "mixup_max_cached_images = 20\n",
    "# Batch size of a single GPU during validation\n",
    "val_batch_size_per_gpu = 8\n",
    "# Worker to pre-fetch data for each single GPU during validation\n",
    "val_num_workers = 3\n",
    "\n",
    "# Config of batch shapes. Only on val.\n",
    "batch_shapes_cfg = dict(\n",
    "    type='BatchShapePolicy',\n",
    "    batch_size=val_batch_size_per_gpu,\n",
    "    img_size=img_scale[0],\n",
    "    size_divisor=32,\n",
    "    extra_pad_ratio=0.5)\n",
    "\n",
    "# -----train val related-----\n",
    "lr_start_factor = 1.0e-5\n",
    "dsl_topk = 13  # Number of bbox selected in each level\n",
    "loss_cls_weight = 1.0\n",
    "loss_bbox_weight = 2.0\n",
    "qfl_beta = 2.0  # beta of QualityFocalLoss\n",
    "weight_decay = 0.05\n",
    "\n",
    "# Save model checkpoint and validation intervals\n",
    "save_checkpoint_intervals = 10\n",
    "# validation intervals in stage 2\n",
    "val_interval_stage2 = 1\n",
    "# The maximum checkpoints to keep.\n",
    "max_keep_ckpts = 3\n",
    "# single-scale training is recommended to\n",
    "# be turned on, which can speed up training.\n",
    "env_cfg = dict(cudnn_benchmark=True)\n",
    "\"\"\"\n",
    "with open(CUSTOM_CONFIG_PATH, 'w') as file:\n",
    "    file.write(CUSTOM_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe8b936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python tools/train.py configs/{model_folder}/{custom_model_name}.py \\\n",
    "#     --resume --cfg-options randomness.seed=42  deterministic=True\\\n",
    "#     | tee \"../log/OUT_{custom_model_name}_$(date +\"%Y%m%d_%H%M%S\").txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5ff9a7-82e1-466c-8953-35de0a006b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /work/van-speech-nlp/jindaznb/j-vis/mmdetection/work_dirs/custom-faster-rcnn_r50_fpn_1x_coco-mutiscale/best_coco_bbox_mAP_50_epoch_298.pth\n",
      "mAP: 0.3276317852230656\n"
     ]
    }
   ],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_IOU_THRESHOLD = 0.5\n",
    "\n",
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset_location}/test\",\n",
    "    annotations_path=f\"{dataset_location}/test/_annotations.coco.json\",\n",
    ")\n",
    "\n",
    "images = list(ds.images.values())\n",
    "CUSTOM_WEIGHTS_PATH = glob.glob(f\"{HOME}/mmdetection/work_dirs/{custom_model_name}/best_coco_bbox_mAP_50_epoch_*.pth\")[-1]\n",
    "model = init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device=DEVICE)\n",
    "\n",
    "def callback(image: np.ndarray) -> sv.Detections:\n",
    "    result = inference_detector(model, image)\n",
    "    detections = sv.Detections.from_mmdetection(result)\n",
    "    return detections[detections.confidence > CONFIDENCE_THRESHOLD].with_nms(threshold=NMS_IOU_THRESHOLD)\n",
    "\n",
    "\n",
    "mean_average_precision = sv.MeanAveragePrecision.benchmark(\n",
    "    dataset = ds,\n",
    "    callback = callback\n",
    ")\n",
    "\n",
    "print('mAP:', mean_average_precision.map50_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366c722-c495-4b59-8f86-ba5ded5fbe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /work/van-speech-nlp/jindaznb/j-vis/mmdetection/work_dirs/custom-faster-rcnn_r50_fpn_1x_coco-mutiscale/best_coco_bbox_mAP_50_epoch_298.pth\n",
      "|   iter    |  target   | confid... | nms_io... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.3249   \u001b[0m | \u001b[0m0.4371   \u001b[0m | \u001b[0m0.9556   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.3409   \u001b[0m | \u001b[95m0.7588   \u001b[0m | \u001b[95m0.6388   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.324    \u001b[0m | \u001b[0m0.2404   \u001b[0m | \u001b[0m0.2404   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.3117   \u001b[0m | \u001b[0m0.1523   \u001b[0m | \u001b[0m0.8796   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.3343   \u001b[0m | \u001b[0m0.641    \u001b[0m | \u001b[0m0.7373   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3634   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.3192   \u001b[0m | \u001b[0m0.3571   \u001b[0m | \u001b[0m0.5562   \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.3467   \u001b[0m | \u001b[95m0.9021   \u001b[0m | \u001b[95m1.0      \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.3463   \u001b[0m | \u001b[0m0.8877   \u001b[0m | \u001b[0m0.9632   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.3099   \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m0.5005   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.3359   \u001b[0m | \u001b[0m0.5047   \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.3202   \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.3369   \u001b[0m | \u001b[0m0.6846   \u001b[0m | \u001b[0m0.9989   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.3319   \u001b[0m | \u001b[0m0.5371   \u001b[0m | \u001b[0m0.3828   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8202   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.3409   \u001b[0m | \u001b[0m0.6437   \u001b[0m | \u001b[0m0.2365   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.3312   \u001b[0m | \u001b[0m0.5945   \u001b[0m | \u001b[0m0.5622   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.3198   \u001b[0m | \u001b[0m0.3731   \u001b[0m | \u001b[0m0.7625   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.345    \u001b[0m | \u001b[0m0.752    \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[95m20       \u001b[0m | \u001b[95m0.3474   \u001b[0m | \u001b[95m0.8991   \u001b[0m | \u001b[95m0.9932   \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset_location}/test\",\n",
    "    annotations_path=f\"{dataset_location}/test/_annotations.coco.json\",\n",
    ")\n",
    "\n",
    "images = list(ds.images.values())\n",
    "CUSTOM_WEIGHTS_PATH = glob.glob(f\"{HOME}/mmdetection/work_dirs/{custom_model_name}/best_coco_bbox_mAP_50_epoch_*.pth\")[-1]\n",
    "model = init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device=DEVICE)\n",
    "\n",
    "best_map, best_params = optimize_params(ds, model, param_space)\n",
    "print('Best mAP:', best_map)\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52a9aa-b187-4d2b-b64a-067380bc7b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb13ae-9724-473a-a1dd-733d6fdaf8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced3453-1687-4c69-b055-85dfba034281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453232e4-683e-4c41-9975-5639b643af04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
