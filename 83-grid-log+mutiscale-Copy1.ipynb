{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408339de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvcc: command not found\n",
      "gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "/bin/bash: nvidia-smi: command not found\n",
      "/work/van-speech-nlp/jindaznb/j-vis\n",
      "System Prefix: /work/van-speech-nlp/jindaznb/visenv\n",
      "HOME: /work/van-speech-nlp/jindaznb/j-vis\n",
      "2.0.0+cu117 False\n",
      "3.3.0\n",
      "11.7\n",
      "GCC 9.3\n"
     ]
    }
   ],
   "source": [
    "%run 1-0mmyolo-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb2054",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Write custom Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8941a869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/j-vis/mmdetection\n"
     ]
    }
   ],
   "source": [
    "# %cd {HOME}/mmyolo\n",
    "%cd {HOME}/mmdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d75896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME: /work/van-speech-nlp/jindaznb/j-vis/mmdetection\n",
      "/work/van-speech-nlp/jindaznb/j-vis/mmdetection/configs/grid_rcnn/custom-grid-rcnn_x101-64x4d_fpn_gn-head_2x_coco-log-muti.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)\n",
    "BATCH_SIZE=8\n",
    "classes=('Alive Tree', 'Beetle-Fire Tree', 'Dead Tree', 'Debris')\n",
    "num_classes=len(classes)\n",
    "\n",
    "\n",
    "model_folder=\"grid_rcnn\"\n",
    "base_model_name=\"grid-rcnn_x101-64x4d_fpn_gn-head_2x_coco\"\n",
    "custom_model_name=f\"custom-{base_model_name}-log-muti\"\n",
    "CUSTOM_CONFIG_PATH = f\"{HOME}/configs/{model_folder}/{custom_model_name}.py\"\n",
    "dataset_location=f\"/work/van-speech-nlp/jindaznb/j-vis/Forestfire2024-1-log\"\n",
    "print(CUSTOM_CONFIG_PATH)\n",
    "\n",
    "\n",
    "CUSTOM_CONFIG = f\"\"\"\n",
    "_base_ = './{base_model_name}.py'\n",
    "\n",
    "# ========================Frequently modified parameters======================\n",
    "# -----data related-----\n",
    "model = dict(\n",
    "    roi_head=dict(\n",
    "        bbox_head=dict(num_classes={num_classes}),\n",
    "))\n",
    "\n",
    "dataset_type = 'COCODataset'\n",
    "classes =  {classes}\n",
    "\n",
    "data_root = '{dataset_location}' # Root directory of the dataset\n",
    "\n",
    "train_ann_file = 'train/_annotations.coco.json'  # Annotation file for training set\n",
    "train_data_prefix = 'train/'  # Prefix for training data directory\n",
    "\n",
    "val_ann_file = 'valid/_annotations.coco.json'  # Annotation file for validation set\n",
    "val_data_prefix = 'valid/'  # Prefix for validation data directory\n",
    "\n",
    "class_name = {classes} \n",
    "num_classes = {num_classes}  # Number of classes in the dataset\n",
    "metainfo = dict(classes=class_name, palette=[(20, 220, 60)])  # Metadata information for visualization\n",
    "\n",
    "train_batch_size_per_gpu = {BATCH_SIZE}  # Batch size per GPU during training\n",
    "#train_num_workers = 4  # Number of worker processes for data loading during training\n",
    "persistent_workers = True  # Whether to use persistent workers during training\n",
    "\n",
    "# -----train val related-----\n",
    "base_lr = 0.004  # Base learning rate for optimization\n",
    "max_epochs = {MAX_EPOCHS}  # Maximum training epochs\n",
    "num_epochs_stage2 = 20  # Number of epochs for stage 2 training\n",
    "\n",
    "model_test_cfg = dict(\n",
    "    multi_label=True,  # Multi-label configuration for multi-class prediction\n",
    "    nms_pre=30000,  # Number of boxes before NMS\n",
    "    score_thr=0.001,  # Score threshold to filter out boxes\n",
    "    nms=dict(type='nms', iou_threshold=0.65),  # NMS type and threshold\n",
    "    max_per_img=300)  # Maximum number of detections per image\n",
    "\n",
    "\n",
    "# ========================Possible modified parameters========================\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        type=\"CheckpointHook\",\n",
    "        save_best=\"coco/bbox_mAP_50\",\n",
    "        rule=\"greater\",\n",
    "        max_keep_ckpts={max_keep_ckpts},\n",
    "    ),\n",
    "    early_stopping=dict(\n",
    "        type=\"EarlyStoppingHook\",\n",
    "        monitor=\"coco/bbox_mAP_50\",\n",
    "        patience={PATIENCE},\n",
    "        min_delta=0.001\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_cfg=dict(\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "\n",
    "data = dict(\n",
    "    samples_per_gpu=8,\n",
    "    #workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='train/',\n",
    "        classes=classes,\n",
    "        img_scale=[(1333, 800), (1666, 1000)], # mutiscale\n",
    "        ann_file='train/_annotations.coco.json.json'),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='valid/',\n",
    "        classes=classes,\n",
    "        ann_file='valid/_annotations.coco.json'),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='test/',\n",
    "        classes=classes,\n",
    "        ann_file='test/_annotations.coco.json'))\n",
    "\n",
    "# -----data related-----\n",
    "img_scale = (1024, 1024)  # width, height\n",
    "# ratio range for random resize\n",
    "random_resize_ratio_range = (0.1, 2.0)\n",
    "# Cached images number in mosaic\n",
    "mosaic_max_cached_images = 40\n",
    "# Number of cached images in mixupep\n",
    "mixup_max_cached_images = 20\n",
    "# Batch size of a single GPU during validation\n",
    "val_batch_size_per_gpu = 8\n",
    "# Worker to pre-fetch data for each single GPU during validation\n",
    "val_num_workers = 3\n",
    "\n",
    "# Config of batch shapes. Only on val.\n",
    "batch_shapes_cfg = dict(\n",
    "    type='BatchShapePolicy',\n",
    "    batch_size=val_batch_size_per_gpu,\n",
    "    img_size=img_scale[0],\n",
    "    size_divisor=32,\n",
    "    extra_pad_ratio=0.5)\n",
    "\n",
    "# -----train val related-----\n",
    "lr_start_factor = 1.0e-5\n",
    "dsl_topk = 13  # Number of bbox selected in each level\n",
    "loss_cls_weight = 1.0\n",
    "loss_bbox_weight = 2.0\n",
    "qfl_beta = 2.0  # beta of QualityFocalLoss\n",
    "weight_decay = 0.05\n",
    "\n",
    "# Save model checkpoint and validation intervals\n",
    "save_checkpoint_intervals = 10\n",
    "# validation intervals in stage 2\n",
    "val_interval_stage2 = 1\n",
    "# The maximum checkpoints to keep.\n",
    "max_keep_ckpts = 3\n",
    "# single-scale training is recommended to\n",
    "# be turned on, which can speed up training.\n",
    "env_cfg = dict(cudnn_benchmark=True)\n",
    "\n",
    "\n",
    "\n",
    "test_dataloader = dict(\n",
    "    dataset=dict(\n",
    "        data_root='{dataset_location}',\n",
    "    ),)\n",
    "test_evaluator = dict(\n",
    "    ann_file='{dataset_location}/valid/_annotations.coco.json',)\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = dict(\n",
    "\n",
    "    dataset=dict(\n",
    "        data_root='{dataset_location}',\n",
    "    ),)\n",
    "\n",
    "val_dataloader = dict(\n",
    "\n",
    "    dataset=dict(\n",
    "\n",
    "        data_root='{dataset_location}',\n",
    "    ),)\n",
    "    \n",
    "    \n",
    "val_evaluator = dict(\n",
    "    ann_file=\n",
    "    '{dataset_location}/valid/_annotations.coco.json',\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "with open(CUSTOM_CONFIG_PATH, 'w') as file:\n",
    "    file.write(CUSTOM_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f216ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python tools/train.py configs/{model_folder}/{custom_model_name}.py \\\n",
    "#     --resume --cfg-options randomness.seed=42 \\\n",
    "#     | tee \"../log/OUT_{custom_model_name}_$(date +\"%Y%m%d_%H%M%S\").txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1420ef21",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m ds \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mDetectionDataset\u001b[38;5;241m.\u001b[39mfrom_coco(\n\u001b[1;32m      5\u001b[0m     images_directory_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     annotations_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/_annotations.coco.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ds\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m---> 10\u001b[0m CUSTOM_WEIGHTS_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mHOME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/work_dirs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcustom_model_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/best_coco_bbox_mAP_50_epoch_*.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m sv\u001b[38;5;241m.\u001b[39mDetections:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_IOU_THRESHOLD = 0.5\n",
    "\n",
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset_location}/test\",\n",
    "    annotations_path=f\"{dataset_location}/test/_annotations.coco.json\",\n",
    ")\n",
    "\n",
    "images = list(ds.images.values())\n",
    "CUSTOM_WEIGHTS_PATH = glob.glob(f\"{HOME}/work_dirs/{custom_model_name}/best_coco_bbox_mAP_50_epoch_*.pth\")[0]\n",
    "model = init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device=DEVICE)\n",
    "\n",
    "def callback(image: np.ndarray) -> sv.Detections:\n",
    "    result = inference_detector(model, image)\n",
    "    detections = sv.Detections.from_mmdetection(result)\n",
    "    return detections[detections.confidence > CONFIDENCE_THRESHOLD].with_nms(threshold=NMS_IOU_THRESHOLD)\n",
    "\n",
    "\n",
    "mean_average_precision = sv.MeanAveragePrecision.benchmark(\n",
    "    dataset = ds,\n",
    "    callback = callback\n",
    ")\n",
    "\n",
    "print('mAP:', mean_average_precision.map50_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57564f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset_location}/test\",\n",
    "    annotations_path=f\"{dataset_location}/test/_annotations.coco.json\",\n",
    ")\n",
    "\n",
    "images = list(ds.images.values())\n",
    "CUSTOM_WEIGHTS_PATH = glob.glob(f\"{HOME}/work_dirs/{custom_model_name}/best_coco_bbox_mAP_50_epoch_*.pth\")[-1]\n",
    "model = init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device=DEVICE)\n",
    "\n",
    "best_map, best_params = optimize_params(ds, model, param_space)\n",
    "print('Best mAP:', best_map)\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3acc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e6c5097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a28b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88defe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
