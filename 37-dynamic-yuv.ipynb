{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad6e204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Mon_Nov_30_19:08:53_PST_2020\n",
      "Cuda compilation tools, release 11.2, V11.2.67\n",
      "Build cuda_11.2.r11.2/compiler.29373293_0\n",
      "gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "Sun Feb 25 00:26:15 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   35C    P8               9W /  70W |      5MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/work/van-speech-nlp/jindaznb/j-vis\n",
      "System Prefix: /work/van-speech-nlp/jenv\n",
      "HOME: /work/van-speech-nlp/jindaznb/j-vis\n",
      "2.0.0+cu117 True\n",
      "3.3.0\n",
      "11.7\n",
      "GCC 9.3\n",
      "set seed successfully\n"
     ]
    }
   ],
   "source": [
    "%run 1-0mmyolo-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c81a8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Write custom Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d024c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/j-vis/mmdetection\n"
     ]
    }
   ],
   "source": [
    "# %cd {HOME}/mmyolo\n",
    "%cd {HOME}/mmdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfeef84-c3fb-4329-ba12-9b61a5c9d535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_location=f\"/work/van-speech-nlp/jindaznb/j-vis/Forestfire2024-1-yuv\"\n",
    "model_name=\"custom-dynamic-rcnn_r50_fpn_1x_coco-yuv\"\n",
    "CUSTOM_CONFIG_PATH = f\"{HOME}/mmdetection/configs/dynamic_rcnn/{model_name}.py\"\n",
    "\n",
    "\n",
    "CUSTOM_CONFIG = f\"\"\"\n",
    "_base_ = '../faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py'\n",
    "\n",
    "\n",
    "\n",
    "# ========================Frequently modified parameters======================\n",
    "# -----data related-----\n",
    "model = dict(\n",
    "    roi_head=dict(\n",
    "        bbox_head=dict(num_classes=4),\n",
    "))\n",
    "\n",
    "dataset_type = 'COCODataset'\n",
    "max_epochs = 200\n",
    "classes =  ('Alive Tree', 'Beetle-Fire Tree', 'Dead Tree', 'Debris') \n",
    "\n",
    "data_root = \"{dataset_location}\" # Root directory of the dataset\n",
    "\n",
    "train_ann_file = 'train/_annotations.coco.json'  # Annotation file for training set\n",
    "train_data_prefix = 'train/'  # Prefix for training data directory\n",
    "\n",
    "val_ann_file = 'valid/_annotations.coco.json'  # Annotation file for validation set\n",
    "val_data_prefix = 'valid/'  # Prefix for validation data directory\n",
    "\n",
    "class_name = ('Alive Tree', 'Beetle-Fire Tree', 'Dead Tree', 'Debris')  \n",
    "num_classes = 4  # Number of classes in the dataset\n",
    "metainfo = dict(classes=class_name, palette=[(20, 220, 60)])  # Metadata information for visualization\n",
    "\n",
    "#train_batch_size_per_gpu = 8  # Batch size per GPU during training\n",
    "#train_num_workers = 4  # Number of worker processes for data loading during training\n",
    "persistent_workers = True  # Whether to use persistent workers during training\n",
    "\n",
    "# -----train val related-----\n",
    "# base_lr = 0.004  # Base learning rate for optimization\n",
    "base_lr = 0.04\n",
    "max_epochs = 200  # Maximum training epochs\n",
    "num_epochs_stage2 = 20  # Number of epochs for stage 2 training\n",
    "\n",
    "model_test_cfg = dict(\n",
    "    multi_label=True,  # Multi-label configuration for multi-class prediction\n",
    "    nms_pre=30000,  # Number of boxes before NMS\n",
    "    score_thr=0.001,  # Score threshold to filter out boxes\n",
    "    nms=dict(type='nms', iou_threshold=0.65),  # NMS type and threshold\n",
    "    max_per_img=300)  # Maximum number of detections per image\n",
    "\n",
    "\n",
    "# ========================Possible modified parameters========================\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        type=\"CheckpointHook\",\n",
    "        save_best=\"coco/bbox_mAP_50\",\n",
    "        rule=\"greater\",\n",
    "        max_keep_ckpts=10,\n",
    "    ),\n",
    "    early_stopping=dict(\n",
    "        type=\"EarlyStoppingHook\",\n",
    "        monitor=\"coco/bbox_mAP_50\",\n",
    "        patience=15,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_cfg=dict(\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "\n",
    "data = dict(\n",
    "    #samples_per_gpu=1,\n",
    "    #workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='train/',\n",
    "        classes=classes,\n",
    "        ann_file='train/_annotations.coco.json.json'),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='valid/',\n",
    "        classes=classes,\n",
    "        ann_file='valid/_annotations.coco.json'),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='test/',\n",
    "        classes=classes,\n",
    "        ann_file='test/_annotations.coco.json'))\n",
    "\n",
    "# -----data related-----\n",
    "img_scale = (1024, 1024)  # width, height\n",
    "# ratio range for random resize\n",
    "random_resize_ratio_range = (0.1, 2.0)\n",
    "# Cached images number in mosaic\n",
    "mosaic_max_cached_images = 40\n",
    "# Number of cached images in mixupep\n",
    "mixup_max_cached_images = 20\n",
    "# Batch size of a single GPU during validation\n",
    "val_batch_size_per_gpu = 8\n",
    "# Worker to pre-fetch data for each single GPU during validation\n",
    "val_num_workers = 3\n",
    "\n",
    "# Config of batch shapes. Only on val.\n",
    "batch_shapes_cfg = dict(\n",
    "    type='BatchShapePolicy',\n",
    "    batch_size=val_batch_size_per_gpu,\n",
    "    img_size=img_scale[0],\n",
    "    size_divisor=32,\n",
    "    extra_pad_ratio=0.5)\n",
    "\n",
    "# -----model related-----\n",
    "# The scaling factor that controls the depth of the network structure\n",
    "deepen_factor = 0.67\n",
    "# The scaling factor that controls the width of the network structure\n",
    "widen_factor = 0.75\n",
    "# Strides of multi-scale prior box\n",
    "strides = [8, 16, 32]\n",
    "\n",
    "norm_cfg = dict(type='BN')  # Normalization config\n",
    "\n",
    "# -----train val related-----\n",
    "lr_start_factor = 1.0e-5\n",
    "dsl_topk = 13  # Number of bbox selected in each level\n",
    "loss_cls_weight = 1.0\n",
    "loss_bbox_weight = 2.0\n",
    "qfl_beta = 2.0  # beta of QualityFocalLoss\n",
    "weight_decay = 0.05\n",
    "\n",
    "# Save model checkpoint and validation intervals\n",
    "save_checkpoint_intervals = 10 \n",
    "# validation intervals in stage 2\n",
    "val_interval_stage2 = 1\n",
    "# The maximum checkpoints to keep.\n",
    "max_keep_ckpts = 3\n",
    "# single-scale training is recommended to\n",
    "# be turned on, which can speed up training.\n",
    "env_cfg = dict(cudnn_benchmark=True)\n",
    "\"\"\"\n",
    "with open(CUSTOM_CONFIG_PATH, 'w') as file:\n",
    "    file.write(CUSTOM_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe8b936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/van-speech-nlp/jindaznb/j-vis/mmdetection/tools/train.py\", line 8, in <module>\n",
      "    from mmengine.runner import Runner\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/mmengine/runner/__init__.py\", line 2, in <module>\n",
      "    from ._flexible_runner import FlexibleRunner\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/mmengine/runner/_flexible_runner.py\", line 10, in <module>\n",
      "    import torch.nn as nn\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/__init__.py\", line 1285, in <module>\n",
      "    from torch import quantization as quantization\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/quantization/__init__.py\", line 1, in <module>\n",
      "    from .quantize import *  # noqa: F403\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/quantization/quantize.py\", line 10, in <module>\n",
      "    from torch.ao.quantization.quantize import _convert\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/ao/quantization/__init__.py\", line 3, in <module>\n",
      "    from .fake_quantize import *  # noqa: F403\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/ao/quantization/fake_quantize.py\", line 8, in <module>\n",
      "    from torch.ao.quantization.observer import (\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/ao/quantization/observer.py\", line 15, in <module>\n",
      "    from torch.ao.quantization.utils import (\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/ao/quantization/utils.py\", line 12, in <module>\n",
      "    from torch.fx import Node\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/fx/__init__.py\", line 88, in <module>\n",
      "    from .interpreter import Interpreter as Interpreter, Transformer as Transformer\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/fx/interpreter.py\", line 371, in <module>\n",
      "    class Transformer(Interpreter):\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/fx/interpreter.py\", line 446, in Transformer\n",
      "    def get_attr(self, target : 'Target', args : Tuple[Argument, ...], kwargs : Dict[str, Any]) -> Proxy:\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/site-packages/torch/fx/_compatibility.py\", line 11, in mark_back_compat\n",
      "    docstring = textwrap.dedent(getattr(fn, '__doc__', None) or '')\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/textwrap.py\", line 469, in dedent\n",
      "    text = re.sub(r'(?m)^' + margin, '', text)\n",
      "  File \"/work/van-speech-nlp/jenv/lib/python3.10/re.py\", line 209, in sub\n",
      "    return _compile(pattern, flags).sub(repl, string, count)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# # !python tools/train.py configs/ssd/costom_ssd512.py --resume | tee ../OUT_ssd.txt\n",
    "!python tools/train.py configs/dynamic_rcnn/custom-dynamic-rcnn_r50_fpn_1x_coco-yuv.py --resume  | tee \"../OUT_dyn_$(date +\"%Y%m%d_%H%M%S\").txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558c9a65-dfb7-46f4-95b4-b1b1a57f33e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/van-speech-nlp/jindaznb/j-vis/Forestfire2024-1-yuv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab52a9aa-b187-4d2b-b64a-067380bc7b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /work/van-speech-nlp/jindaznb/j-vis/mmdetection/work_dirs/custom-dynamic-rcnn_r50_fpn_1x_coco-yuv/best_coco_bbox_mAP_50_epoch_189.pth\n",
      "|   iter    |  target   | confid... | nms_io... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.04209  \u001b[0m | \u001b[0m0.4371   \u001b[0m | \u001b[0m0.9556   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.08368  \u001b[0m | \u001b[95m0.7588   \u001b[0m | \u001b[95m0.6388   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.04055  \u001b[0m | \u001b[0m0.2404   \u001b[0m | \u001b[0m0.2404   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.03693  \u001b[0m | \u001b[0m0.1523   \u001b[0m | \u001b[0m0.8796   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.06134  \u001b[0m | \u001b[0m0.641    \u001b[0m | \u001b[0m0.7373   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.07129  \u001b[0m | \u001b[0m0.9129   \u001b[0m | \u001b[0m0.5792   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.08045  \u001b[0m | \u001b[0m0.7101   \u001b[0m | \u001b[0m0.4667   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.06432  \u001b[0m | \u001b[0m0.8691   \u001b[0m | \u001b[0m0.1351   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9538   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.06288  \u001b[0m | \u001b[0m0.5899   \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.0779   \u001b[0m | \u001b[0m0.9953   \u001b[0m | \u001b[0m0.3472   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.04453  \u001b[0m | \u001b[0m0.5006   \u001b[0m | \u001b[0m0.5108   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.05876  \u001b[0m | \u001b[0m0.8354   \u001b[0m | \u001b[0m0.3691   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.08243  \u001b[0m | \u001b[0m0.7481   \u001b[0m | \u001b[0m0.638    \u001b[0m |\n",
      "| \u001b[95m15       \u001b[0m | \u001b[95m0.08554  \u001b[0m | \u001b[95m0.9993   \u001b[0m | \u001b[95m0.1995   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.0807   \u001b[0m | \u001b[0m0.9977   \u001b[0m | \u001b[0m0.1988   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.08032  \u001b[0m | \u001b[0m0.9977   \u001b[0m | \u001b[0m0.2225   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.0832   \u001b[0m | \u001b[0m0.7548   \u001b[0m | \u001b[0m0.6589   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.03977  \u001b[0m | \u001b[0m0.2035   \u001b[0m | \u001b[0m0.2786   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.05399  \u001b[0m | \u001b[0m0.7804   \u001b[0m | \u001b[0m0.6571   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.082    \u001b[0m | \u001b[0m0.7349   \u001b[0m | \u001b[0m0.6578   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.08227  \u001b[0m | \u001b[0m0.7411   \u001b[0m | \u001b[0m0.6838   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.059    \u001b[0m | \u001b[0m0.8373   \u001b[0m | \u001b[0m0.7127   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.08049  \u001b[0m | \u001b[0m0.7149   \u001b[0m | \u001b[0m0.6818   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.08126  \u001b[0m | \u001b[0m0.7306   \u001b[0m | \u001b[0m0.7111   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.07949  \u001b[0m | \u001b[0m0.6994   \u001b[0m | \u001b[0m0.7171   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.08065  \u001b[0m | \u001b[0m0.7216   \u001b[0m | \u001b[0m0.7459   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.0833   \u001b[0m | \u001b[0m0.7558   \u001b[0m | \u001b[0m0.738    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.08246  \u001b[0m | \u001b[0m0.7451   \u001b[0m | \u001b[0m0.772    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.05366  \u001b[0m | \u001b[0m0.7785   \u001b[0m | \u001b[0m0.7661   \u001b[0m |\n",
      "=================================================\n",
      "Best mAP: 0.08554179273991\n",
      "Best Parameters: [0.999265398828279, 0.1995089187717251]\n"
     ]
    }
   ],
   "source": [
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset_location}/test\",\n",
    "    annotations_path=f\"{dataset_location}/test/_annotations.coco.json\",\n",
    ")\n",
    "\n",
    "images = list(ds.images.values())\n",
    "CUSTOM_WEIGHTS_PATH = glob.glob(f\"{HOME}/mmdetection/work_dirs/{model_name}/best_coco_bbox_mAP_50_epoch_*.pth\")[-1]\n",
    "model = init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device=DEVICE)\n",
    "\n",
    "best_map, best_params = optimize_params(ds, model, param_space)\n",
    "print('Best mAP:', best_map)\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb13ae-9724-473a-a1dd-733d6fdaf8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced3453-1687-4c69-b055-85dfba034281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453232e4-683e-4c41-9975-5639b643af04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
