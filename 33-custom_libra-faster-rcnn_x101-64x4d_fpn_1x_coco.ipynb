{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad6e204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Mon_Nov_30_19:08:53_PST_2020\n",
      "Cuda compilation tools, release 11.2, V11.2.67\n",
      "Build cuda_11.2.r11.2/compiler.29373293_0\n",
      "gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "Thu Feb 22 02:40:05 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              27W /  70W |      2MiB / 15360MiB |      7%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/work/van-speech-nlp/jindaznb/j-vis\n",
      "System Prefix: /work/van-speech-nlp/jenv\n",
      "HOME: /work/van-speech-nlp/jindaznb/j-vis\n",
      "2.0.0+cu117 True\n",
      "3.3.0\n",
      "11.7\n",
      "GCC 9.3\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Forestfire2024-1 to coco-mmdetection:: 100%|██████████| 151008/151008 [00:02<00:00, 74809.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Forestfire2024-1 in coco-mmdetection:: 100%|██████████| 681/681 [00:05<00:00, 123.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset classes: ['Alive Tree', 'Beetle-Fire Tree', 'Dead Tree', 'Debris']\n",
      "dataset size: 471\n",
      "dataset classes: ['Alive Tree', 'Beetle-Fire Tree', 'Dead Tree', 'Debris']\n",
      "dataset size: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 02:40:47.159272: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-22 02:40:47.203972: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-22 02:40:47.203997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-22 02:40:47.205059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-22 02:40:47.212324: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 02:40:51.238785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%run 1-0mmyolo-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c81a8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Write custom Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091d7a1-f5e0-43b2-b5b3-49f3d61e6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd {HOME}/mmyolo\n",
    "%cd {HOME}/mmdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd27f910-de3a-455a-909d-153c9b119e56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HOME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m base_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibra-faster-rcnn_x101-64x4d_fpn_1x_coco\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m custom_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m CUSTOM_CONFIG_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHOME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/mmdetection/configs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustom_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(CUSTOM_CONFIG_PATH)\n\u001b[1;32m      8\u001b[0m CUSTOM_CONFIG \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m_base_ = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124menv_cfg = dict(cudnn_benchmark=True)\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HOME' is not defined"
     ]
    }
   ],
   "source": [
    "model_folder=\"libra_rcnn\"\n",
    "base_model_name=\"libra-faster-rcnn_x101-64x4d_fpn_1x_coco\"\n",
    "custom_model_name=f\"custom-{base_model_name}\"\n",
    "CUSTOM_CONFIG_PATH = f\"{HOME}/mmdetection/configs/{model_folder}/{custom_model_name}.py\"\n",
    "print(CUSTOM_CONFIG_PATH)\n",
    "\n",
    "\n",
    "CUSTOM_CONFIG = f\"\"\"\n",
    "_base_ = './{base_model_name}.py'\n",
    "\n",
    "# ========================Frequently modified parameters======================\n",
    "# -----data related-----\n",
    "model = dict(\n",
    "    roi_head=dict(\n",
    "        bbox_head=dict(num_classes={num_classes}),\n",
    "))\n",
    "\n",
    "dataset_type = 'COCODataset'\n",
    "classes =  {classes}\n",
    "\n",
    "data_root = '{dataset_location}' # Root directory of the dataset\n",
    "\n",
    "train_ann_file = 'train/_annotations.coco.json'  # Annotation file for training set\n",
    "train_data_prefix = 'train/'  # Prefix for training data directory\n",
    "\n",
    "val_ann_file = 'valid/_annotations.coco.json'  # Annotation file for validation set\n",
    "val_data_prefix = 'valid/'  # Prefix for validation data directory\n",
    "\n",
    "class_name = {classes} \n",
    "num_classes = {num_classes}  # Number of classes in the dataset\n",
    "metainfo = dict(classes=class_name, palette=[(20, 220, 60)])  # Metadata information for visualization\n",
    "\n",
    "train_batch_size_per_gpu = {BATCH_SIZE}  # Batch size per GPU during training\n",
    "#train_num_workers = 4  # Number of worker processes for data loading during training\n",
    "persistent_workers = True  # Whether to use persistent workers during training\n",
    "\n",
    "# -----train val related-----\n",
    "# base_lr = 0.004  # Base learning rate for optimization\n",
    "base_lr = 0.04\n",
    "max_epochs = {MAX_EPOCHS}  # Maximum training epochs\n",
    "num_epochs_stage2 = 20  # Number of epochs for stage 2 training\n",
    "\n",
    "model_test_cfg = dict(\n",
    "    multi_label=True,  # Multi-label configuration for multi-class prediction\n",
    "    nms_pre=30000,  # Number of boxes before NMS\n",
    "    score_thr=0.001,  # Score threshold to filter out boxes\n",
    "    nms=dict(type='nms', iou_threshold=0.65),  # NMS type and threshold\n",
    "    max_per_img=300)  # Maximum number of detections per image\n",
    "\n",
    "\n",
    "# ========================Possible modified parameters========================\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        type=\"CheckpointHook\",\n",
    "        save_best=\"coco/bbox_mAP_50\",\n",
    "        rule=\"greater\",\n",
    "        max_keep_ckpts=10,\n",
    "    ),\n",
    "    early_stopping=dict(\n",
    "        type=\"EarlyStoppingHook\",\n",
    "        monitor=\"coco/bbox_mAP_50\",\n",
    "        patience=15,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_cfg=dict(\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "\n",
    "data = dict(\n",
    "    #samples_per_gpu=1,\n",
    "    #workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='train/',\n",
    "        classes=classes,\n",
    "        ann_file='train/_annotations.coco.json.json'),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='valid/',\n",
    "        classes=classes,\n",
    "        ann_file='valid/_annotations.coco.json'),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        img_prefix='test/',\n",
    "        classes=classes,\n",
    "        ann_file='test/_annotations.coco.json'))\n",
    "\n",
    "# -----data related-----\n",
    "img_scale = (1024, 1024)  # width, height\n",
    "# ratio range for random resize\n",
    "random_resize_ratio_range = (0.1, 2.0)\n",
    "# Cached images number in mosaic\n",
    "mosaic_max_cached_images = 40\n",
    "# Number of cached images in mixupep\n",
    "mixup_max_cached_images = 20\n",
    "# Batch size of a single GPU during validation\n",
    "val_batch_size_per_gpu = 8\n",
    "# Worker to pre-fetch data for each single GPU during validation\n",
    "val_num_workers = 3\n",
    "\n",
    "# Config of batch shapes. Only on val.\n",
    "batch_shapes_cfg = dict(\n",
    "    type='BatchShapePolicy',\n",
    "    batch_size=val_batch_size_per_gpu,\n",
    "    img_size=img_scale[0],\n",
    "    size_divisor=32,\n",
    "    extra_pad_ratio=0.5)\n",
    "\n",
    "# -----train val related-----\n",
    "lr_start_factor = 1.0e-5\n",
    "dsl_topk = 13  # Number of bbox selected in each level\n",
    "loss_cls_weight = 1.0\n",
    "loss_bbox_weight = 2.0\n",
    "qfl_beta = 2.0  # beta of QualityFocalLoss\n",
    "weight_decay = 0.05\n",
    "\n",
    "# Save model checkpoint and validation intervals\n",
    "save_checkpoint_intervals = 10\n",
    "# validation intervals in stage 2\n",
    "val_interval_stage2 = 1\n",
    "# The maximum checkpoints to keep.\n",
    "max_keep_ckpts = 3\n",
    "# single-scale training is recommended to\n",
    "# be turned on, which can speed up training.\n",
    "env_cfg = dict(cudnn_benchmark=True)\n",
    "\"\"\"\n",
    "with open(CUSTOM_CONFIG_PATH, 'w') as file:\n",
    "    file.write(CUSTOM_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e771f-cee8-448c-b8de-6622f9405390",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## !python tools/train.py configs/ssd/costom_ssd512.py --resume | tee ../OUT_ssd.txt\n",
    "!python tools/train.py configs/libra_rcnn/custom_libra-faster-rcnn_x101-64x4d_fpn_1x_coco.py | tee ../OUT_libra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0366c722-c495-4b59-8f86-ba5ded5fbe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117 True\n",
      "3.3.0\n",
      "11.7\n",
      "GCC 9.3\n",
      "HOME: /work/van-speech-nlp/jindaznb/j-vis/mmdetection\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Forestfire2024-1 to coco-mmdetection:: 100%|██████████| 151008/151008 [00:02<00:00, 55775.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Forestfire2024-1 in coco-mmdetection:: 100%|██████████| 681/681 [00:06<00:00, 108.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /work/van-speech-nlp/jindaznb/j-vis/mmdetection/work_dirs/custom_libra-faster-rcnn_x101-64x4d_fpn_1x_coco/best_coco_bbox_mAP_50_epoch_199.pth\n",
      "Best mAP: 0.4595606769745987\n",
      "Best Parameters: [0.9526315789473684, 0.5736842105263158]\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import roboflow\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check MMDetection installation\n",
    "from mmengine.utils import get_git_hash\n",
    "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
    "\n",
    "import mmdet\n",
    "\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"a8fzziqukkQgsmGFnKgD\")\n",
    "project = rf.workspace(\"wildfire2024\").project(\"forestfire2024\")\n",
    "dataset = project.version(1).download(\"coco-mmdetection\")\n",
    "\n",
    "CUSTOM_WEIGHTS_PATH = f\"{HOME}/work_dirs/custom_libra-faster-rcnn_x101-64x4d_fpn_1x_coco/best_coco_bbox_mAP_50_epoch_199.pth\"\n",
    "CUSTOM_CONFIG_PATH = f\"{HOME}/configs/libra_rcnn/custom_libra-faster-rcnn_x101-64x4d_fpn_1x_coco.py\"\n",
    "model = init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device=DEVICE)\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset.location}/test\",\n",
    "    annotations_path=f\"{dataset.location}/test/_annotations.coco.json\",\n",
    ")\n",
    "\n",
    "images = list(ds.images.values())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset.location}/test\",\n",
    "    annotations_path=f\"{dataset.location}/test/_annotations.coco.json\",\n",
    ")\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_space = {\n",
    "    'CONFIDENCE_THRESHOLD': np.logspace(np.log10(0.001), 0, 20),  # Adjust the range as needed\n",
    "    'NMS_IOU_THRESHOLD': np.logspace(np.log10(0.001), 0, 20),  # Adjust the range as needed\n",
    "}\n",
    "\n",
    "best_map = 0.0\n",
    "best_params = {}\n",
    "\n",
    "# Perform random search\n",
    "for _ in range(20):  # You can adjust the number of random samples\n",
    "    CONFIDENCE_THRESHOLD= np.random.choice(param_space['CONFIDENCE_THRESHOLD'])\n",
    "    NMS_IOU_THRESHOLD= np.random.choice(param_space['NMS_IOU_THRESHOLD'])\n",
    "    \n",
    "    def callback(image: np.ndarray) -> sv.Detections:\n",
    "        result = inference_detector(model, image)\n",
    "        detections = sv.Detections.from_mmdetection(result)\n",
    "        return detections[detections.confidence > CONFIDENCE_THRESHOLD].with_nms(threshold=NMS_IOU_THRESHOLD)\n",
    "\n",
    "    mean_average_precision = sv.MeanAveragePrecision.benchmark(dataset=ds, callback=callback)\n",
    "\n",
    "    if mean_average_precision.map50_95 > best_map:\n",
    "        best_map = mean_average_precision.map50_95\n",
    "        best_params = [CONFIDENCE_THRESHOLD,NMS_IOU_THRESHOLD]\n",
    "\n",
    "print('Best mAP:', best_map)\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddbfa9-bb09-4efe-a341-5bc2a478fd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789881bd-cd1f-4576-bb71-7b3f9da410e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
